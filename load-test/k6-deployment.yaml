---
apiVersion: v1
kind: ConfigMap
metadata:
  name: k6-script
  namespace: default
data:
  load-test.js: |
    import http from 'k6/http';
    import { check, sleep } from 'k6';
    import { Rate, Trend } from 'k6/metrics';

    // Custom metrics
    const errorRate = new Rate('errors');
    const inferenceLatency = new Trend('inference_latency');

    // Random text generation for prompts
    const topics = [
      'Explain quantum computing',
      'What is machine learning',
      'Describe the solar system',
      'How does photosynthesis work',
      'What is artificial intelligence',
      'Explain blockchain technology',
      'Describe the water cycle',
      'What is climate change',
      'How do computers work',
      'Explain the theory of relativity',
      'What is DNA',
      'Describe the human brain',
      'How does the internet work',
      'What is renewable energy',
      'Explain the stock market',
    ];

    const questions = [
      'in simple terms?',
      'to a 10 year old?',
      'with examples?',
      'in detail?',
      'briefly?',
      'step by step?',
      'with analogies?',
      'for beginners?',
    ];

    function generateRandomPrompt() {
      const topic = topics[Math.floor(Math.random() * topics.length)];
      const question = questions[Math.floor(Math.random() * questions.length)];
      return `${topic} ${question}`;
    }

    // Load test configuration
    export const options = {
      stages: [
        { duration: '2m', target: 15 },  // Quick ramp up to 15 VUs
        { duration: '55m', target: 15 }, // Hold at 15 VUs for 55 minutes
        { duration: '3m', target: 0 },   // Ramp down
      ],
      thresholds: {
        http_req_duration: ['p(95)<10000'], // 95% of requests should be below 10s
        errors: ['rate<0.1'],                // Error rate should be below 10%
      },
    };

    export default function () {
      const NLB_ENDPOINT = __ENV.NLB_ENDPOINT || 'http://vllm-serve-serve-svc:8000';
      
      const prompt = generateRandomPrompt();
      const maxTokens = Math.floor(Math.random() * 100) + 50; // 50-150 tokens
      
      const payload = JSON.stringify({
        prompt: prompt,
        max_tokens: maxTokens,
        temperature: 0.7,
      });

      const params = {
        headers: {
          'Content-Type': 'application/json',
        },
        timeout: '30s',
      };

      const startTime = Date.now();
      const response = http.post(`${NLB_ENDPOINT}/infer`, payload, params);
      const duration = Date.now() - startTime;

      // Record metrics
      inferenceLatency.add(duration);
      
      const success = check(response, {
        'status is 200': (r) => r.status === 200,
        'has generated_text': (r) => {
          try {
            const body = JSON.parse(r.body);
            return body.generated_text !== undefined;
          } catch (e) {
            return false;
          }
        },
        'response time < 15s': (r) => r.timings.duration < 15000,
      });

      errorRate.add(!success);

      // Add some think time between requests
      sleep(Math.random() * 2 + 1); // 1-3 seconds
    }
---
apiVersion: v1
kind: Service
metadata:
  name: k6-web-ui
  namespace: default
spec:
  type: ClusterIP
  ports:
  - port: 5665
    targetPort: 5665
    name: web
  selector:
    app: k6-load-test
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: k6-load-test
  namespace: default
spec:
  replicas: 1
  selector:
    matchLabels:
      app: k6-load-test
  template:
    metadata:
      labels:
        app: k6-load-test
    spec:
      containers:
      - name: k6
        image: grafana/k6:latest
        command:
        - /bin/sh
        - -c
        - |
          # Get NLB endpoint
          NLB_ENDPOINT=$(kubectl get svc ray-serve-nlb -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null)
          
          if [ -z "$NLB_ENDPOINT" ]; then
            echo "Warning: Could not get NLB hostname, using internal service"
            export NLB_ENDPOINT="http://vllm-serve-serve-svc:8000"
          else
            export NLB_ENDPOINT="http://${NLB_ENDPOINT}"
          fi
          
          echo "Testing endpoint: $NLB_ENDPOINT"
          echo "Starting load test..."
          
          # Run k6 with web dashboard
          k6 run --out web-dashboard=export=/tmp/report.html /scripts/load-test.js
          
          echo "Load test completed!"
          echo "Keeping container alive for log viewing..."
          tail -f /dev/null
        env:
        - name: K6_WEB_DASHBOARD
          value: "true"
        - name: K6_WEB_DASHBOARD_EXPORT
          value: "/tmp/k6-report.html"
        - name: K6_WEB_DASHBOARD_PORT
          value: "5665"
        volumeMounts:
        - name: k6-script
          mountPath: /scripts
        resources:
          requests:
            memory: "256Mi"
            cpu: "500m"
          limits:
            memory: "512Mi"
            cpu: "1000m"
      volumes:
      - name: k6-script
        configMap:
          name: k6-script
      serviceAccountName: default
